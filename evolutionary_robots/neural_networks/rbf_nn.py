"""Docstring for rbf_nn.py module

This module implements the Radial Basis Function Network
The network requires a different kind of layer
to take input as a vector, compute the radial basis function
output of that input vector and then pass it to a StaticLayer
to give the output
"""

import numpy as np
import pickle
from graphviz import Digraph
from layers import StaticLayer, RBFLayer
from activation_functions import LinearActivation

import warnings
		
# Gaussian Radial Basis Network
class GaussianRBFNetwork:
	"""
	The Gaussian Radial Basis Network Class
	The RBF works by calculating the output of radial basis function
	(Gaussian in this case) of the distance measure(euclidean distance
	in this case) between the input vector and the center vectors
	of the neurons of RBFLayer. This Neural Network consists of an
	input layer, a hidden layer and an output layer.
	
	...
	
	Attributes
	----------
	input_dim: integer
		The input dimensions of the Neural Network
	
	hidden_dim: integer
		The dimensions of the hidden layer of the Neural Network
		
	output_dim: integer
		The output dimensions of the Neural Network
		
	beta(optional): integer
		The parameter of the Gaussian Function
		
	Methods
	-------
	forward_propagate(input_vector)
		Generates the output of the Neural Network given the input_vector
		
	save_parameters_to_file(file_name)
		Saves the parameters of the Neural Network to an external file named as file_name
		
	load_parameters_from_file(file_name)
		Loads the parameters of the Neural Network from an external file named as file_name
		
	return_parameters_as_vectors()
		Returns the parameters of the vector organized in the form of a vector
		
	load_parameters_from_vector(weight_vector)
		Load the parameters of the Neural Network from a user input in the form of an array/vector
		
	generate_visual(filename, view=False)
		Generate the visual representation of the Neural Network
		
	Additional Methods
	------------------
	distance_function(input_vector, center_matrix)
		The distance function that the RBF network uses
		
	basis_function(input_vector, beta)
		The radial basis function
		
	Notes
	-----
	Linear Activation with default parameters is used for the static layer
	Along with zero bias
	"""
	def __init__(self, input_dim, hidden_dim, output_dim, beta=1):
		# Make the dimensions available
		self.input_dim = (input_dim, )
		self.hidden_dim = hidden_dim
		self.output_dim = output_dim
	
		# A combination of RBF Layer and StaticLayer
		self.rbf_layer = RBFLayer(input_dim, hidden_dim, self.distance_function, self.basis_function, beta, "RBF Layer")
		self.static_layer = StaticLayer(hidden_dim, output_dim, LinearActivation(), "Static Layer")
		
		# The bias of the perceptron is zero
		self.static_layer.set_bias_vector(np.zeros(output_dim))
		
		# Set the visual
		self.visual = Digraph(comment="RBF Network", graph_attr={'rankdir': "LR", 'splines': "line"}, node_attr={'fixedsize': "true", 'label': ""})
		
	# Forward Propagation
	def forward_propagate(self, input_vector):
		"""
		Generate the output of the Neural Network when input_vector
		is passed to the Neural Network
		
		Parameters
		----------
		input_vector: array_like
			The input_vector to be passed to the Neural Network
			
		Returns
		-------
		intermediate_output: array_like
			The output vector that is generated by the Neural Network
			
		Raises
		------
		ValueException
			The input_vector should be of the dimensions of the input of the network
			
		Notes
		-----
		The output for this network is not so complex, since we have only 3 layers.
		"""
		# Convert to numpy
		input_vector = np.array(input_vector)
		
		# CHeck dimensions
		if(input_vector.shape != self.input_dim):
			raise ValueError("The input dimensions do not match!")
		
		# Calculate Outputs
		intermediate_output = self.rbf_layer.forward_propagate(input_vector)
		intermediate_output = self.static_layer.forward_propagate(intermediate_output)
		
		return intermediate_output
		
	# The distance function of the network
	def distance_function(self, input_vector, center_matrix):
		""" The distance function of the network """
		# Convert to numpy
		input_vector = np.array(input_vector)
		center_matrix = np.array(center_matrix)
		
		# Take the difference
		# Numpy handles it automatically
		difference = center_matrix - input_vector
		
		# Calculate the euclidean distance
		square = difference * difference
		euclidean_distance = np.sqrt(np.sum(square, axis=1))
		
		return euclidean_distance
		
	# The basis function of the network
	def basis_function(self, input_vector, beta):
		""" The basis function of the network """
		# Convert to numpy
		input_vector = np.array(input_vector)
		input_vector = beta * input_vector
		
		# Gaussian function
		square = input_vector * input_vector
		output = np.exp(-1 * square)
		
		return output
		
	# Function to save the layer parameters
	def save_parameters_to_file(self, file_name):
		"""
		Save the parameters of the Neural Network
		
		Using pickle, the list of layers is stored
		"""
		# Use pickle to save the layer_vector
		with open(file_name, 'wb') as f:
			pickle.dump({'rbf': self.rbf_layer, 'static': self.static_layer}, f)
			
	# Function to load the layer parameters
	def load_parameters_from_file(self, file_name):
		""" Load the parameters of the Neural Network """
		# Use pickle to load the layer_vector
		with open(file_name, 'rb') as f:
			data = pickle.load(f)
			self.rbf_layer = data['rbf']
			self.perceptron_layer = data['static']
			
	# Function to return the centers and weights in the form of a vector
	def return_parameters_as_vector(self):
		"""
		Return the parameters of the Neural Network in the form of
		a an array / vector.
		
		Parameters
		----------
		None
		
		Returns
		-------
		output: array_like
			The vector representation of the parameters of the Neural Network
			
		Raises
		------
		None
		"""
		# The vector we get from flattening the center matrix
		# flatten() works in row major order
		center_vector = self.rbf_layer.get_center_matrix().flatten()
		
		# The weight vector
		weight_vector = self.static.get_weight_matrix().flatten()
		
		# The output vector is concatenated form of center_vector and weight_vector
		output = np.concatenate([center_vector, weight_vector])
		
		return output
		
	# Function to load the parameters from vector
	def load_parameters_from_vector(self, parameter_vector):
		"""
		Load the parameters of the Static Neural Network in the form of
		an array / vector
		
		Parameters
		----------
		parameter_vector: array_like
			The parameter vector follows the layout as
			[c_11, c_21, c_31, c_12, c_22, c_32, c_13, c_23, c_33, w_11, w_21, w_12, w_22, w_13, w_23 ...]
			Here, w_ij implies the weight between ith input node and jth output node.
			      c_ij implies the ith parameter of center of jth neuron.
			
		Returns
		-------
		None
		
		Raises
		------
		ValueException
			The parameter array is shorter than required
			
		Warning
			The parameter array is greater than required
		"""
		# Convert to numpy array
		parameter_vector = np.array(parameter_vector)
		
		# Get the dimensions of the center and weight matrix
		center_dim = self.rbf_layer.get_center_dim()
		weight_dim = self.static_layer.get_weight_dim()
		
		
		# Get the interval at which the center and weight seperate
		interval = center_dim[0] * center_dim[1]
		
		# Seperate the weights and bias and then reshape them
		# Numpy raises a None Type Exception, as it cannot reshape a None object
		# If such an excpetion occurs, raise a value error as our parameter_vector
		# is shorter than required
		try:
			# Seperate the center matrix and weight matrix
			self.rbf_layer.set_center_matrix(parameter_vector[:interval].reshape(center_dim))
			self.static_layer.set_weight_matrix(parameter_vector[interval:].reshape(weight_dim))
		except:
			raise ValueError("The parameter vector consists of elements less than required")
			
		# The interval counter should contain the number of elements in parameter_vector
		# Otherwise the user has specified parameters more than required
		# Just a warning is enough
		if(len(parameter_vector) > interval + weight_dim[0] * weight_dim[1]):
			warnings.warn("The parameter vector consists of elements greater than required")
			
		
		
	def generate_visual(self, filename, view=False):
		"""
		Generate the visual representation of the Neural Network and
		store it as a pdf file in the representations directory
		
		Parameters
		----------
		filename
			Specifies the name of the pdf file which is to be saved
			
		view=False
			Whether to view the generated file(True) or not(False)
			
		Returns
		-------
		None
		
		Raises
		------
		None
		
		Note
		----
		Graphviz library is used to generate the representation
		"""
		# We need three subgraphs
		subgraph_one = Digraph(name="cluster_0", graph_attr={'color': "white", 'label': "Input Layer"}, node_attr={'style': "solid", 'color': "blue4", 'shape': "circle"})
		for node_number in range(self.input_dim):
			subgraph_one.node("x" + str(node_number+1))
			
		subgraph_two = Digraph(name="cluster_1", graph_attr={'color': "white", 'label': "RBF Layer"}, node_attr={'style': "solid", 'color': "green", 'shape': "circle"})
		for node_number in range(self.hidden_dim):
			subgraph_two.node("r" + str(node_number+1))
			
		subgraph_three = Digraph(name="cluster_2", graph_attr={'color': 'white', 'label': "Static Layer"}, node_attr={'style': "solid", 'color': "red2", 'shape': "circle"})
		for node_number in range(self.output_dim):
			subgraph_three.node("y" + str(node_number+1))
			
		# Declare subgraphs
		self.visual.subgraph(subgraph_one)
		self.visual.subgraph(subgraph_two)
		self.visual.subgraph(subgraph_three)
		
		# Put the edges in the graph
		for input_node in range(self.input_dim):
			for hidden_node in range(self.hidden_dim):
				self.visual.edge('x'+str(input_node+1), 'r'+str(hidden_node+1))
				
		for hidden_node in range(self.hidden_dim):
			for output_node in range(self.output_dim):
				self.visual.edge('r'+str(hidden_node+1), 'y'+str(output_node+1))
		
		# Render the graph		
		self.visual.render('representations/' + filename + '.gv', view=view)
		
	
		
		
		

